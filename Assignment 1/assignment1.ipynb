{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Would Play with Logistic Regression (adopted from my hw3)\n",
    "\n",
    "# import gzip\n",
    "# from collections import defaultdict\n",
    "# import random\n",
    "\n",
    "# # Load data with functions from stub\n",
    "# def readGz(path):\n",
    "#     for l in gzip.open(path, 'rt'):\n",
    "#         yield eval(l)\n",
    "\n",
    "# def readJSON(path):\n",
    "#     for l in gzip.open(path, 'rt'):\n",
    "#         d = eval(l)\n",
    "#         u = d['userID']\n",
    "#         try:\n",
    "#             g = d['gameID']\n",
    "#         except Exception as e:  # In case the 'gameID' attribute is missing.\n",
    "#             g = None\n",
    "#         yield u, g, d\n",
    "\n",
    "# allHours = []\n",
    "# for l in readJSON(\"train.json.gz\"):\n",
    "#     allHours.append(l)\n",
    "\n",
    "# # Split the data into training and validation sets.\n",
    "# hoursTrain = allHours[:165000]\n",
    "# hoursValid = allHours[165000:]\n",
    "\n",
    "# # Data structures for the would-play baseline (from baseline.py)\n",
    "# gameCount = defaultdict(int)  # Dictionary to keep track of how many times each game was played.\n",
    "# totalPlayed = 0  # Total number of games played.\n",
    "\n",
    "# # Find out which games a user hasn't played yet.\n",
    "# userPlayedGames = defaultdict(set)\n",
    "\n",
    "# # Populate gameCount dictionary and totalPlayed count.\n",
    "# for user, game, _ in readJSON(\"train.json.gz\"):\n",
    "#     gameCount[game] += 1\n",
    "#     totalPlayed += 1\n",
    "#     userPlayedGames[user].add(game)\n",
    "    \n",
    "# # Sort games by popularity (number of times played).\n",
    "# mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "# mostPopular.sort()\n",
    "# mostPopular.reverse()\n",
    "\n",
    "# gamePopularity = {}\n",
    "# for g in gameCount.keys():\n",
    "#     idx = mostPopular.index((gameCount[g],g))\n",
    "#     gamePopularity[g] = 1.0 - idx/len(mostPopular)\n",
    "\n",
    "# # Create validation set which includes both positive and negative samples.\n",
    "# allGames = list(gameCount.keys())  # All distinct games in our dataset.\n",
    "# validationSet = []\n",
    "\n",
    "# # Generate negative samples for the valid set.\n",
    "# for user, game, _ in hoursValid:\n",
    "#     negativeGame = random.choice(allGames)\n",
    "#     while negativeGame in userPlayedGames[user]:\n",
    "#         negativeGame = random.choice(allGames)\n",
    "#     validationSet.append((user, game, 1))        # Positive example: The actual game played by the user\n",
    "#     validationSet.append((user, negativeGame, 0)) # Negative example: A randomly chosen game (not played by the user)\n",
    "\n",
    "# # Create a dictionary with games as keys and sets of users who played them as values.\n",
    "# gameUsers = defaultdict(set)\n",
    "# for user, game, _ in hoursTrain:\n",
    "#     gameUsers[game].add(user)\n",
    "\n",
    "# # Calculate Jaccard similarity between two sets.\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     intersection = len(set1 & set2)\n",
    "#     union = len(set1 | set2)\n",
    "#     return intersection / union if union != 0 else 0\n",
    "\n",
    "# # Precompute Jaccard similarities for all game pairs.\n",
    "# game_pair_similarities = defaultdict(dict)\n",
    "# all_games = list(gameUsers.keys())\n",
    "\n",
    "# for i, game1 in enumerate(all_games):\n",
    "#     for j, game2 in enumerate(all_games):\n",
    "#         if j <= i:\n",
    "#             continue  # No need to compute similarity twice for the same pair\n",
    "#         similarity = jaccard_similarity(gameUsers[game1], gameUsers[game2])\n",
    "#         game_pair_similarities[game1][game2] = similarity\n",
    "#         game_pair_similarities[game2][game1] = similarity\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Prepare the features and labels.\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for user, game, actual in validationSet:\n",
    "#     # Feature 1: Jaccard similarity\n",
    "#     max_similarity = 0\n",
    "#     for game_prime in userPlayedGames[user]:\n",
    "#         if game_prime in game_pair_similarities[game]:\n",
    "#             similarity = game_pair_similarities[game][game_prime]\n",
    "#             max_similarity = max(max_similarity, similarity)\n",
    "#     # Feature 2: Popularity\n",
    "#     popularity = gamePopularity[game]\n",
    "#     X.append([max_similarity, popularity])\n",
    "#     y.append(actual)\n",
    "\n",
    "# # Train a logistic regression model.\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(X, y)\n",
    "\n",
    "# # Predict on the validation set.\n",
    "# y_pred = clf.predict(X)\n",
    "\n",
    "# # Open the test file and prediction file.\n",
    "# predictions = open(\"predictions_Played.csv\", 'w')\n",
    "\n",
    "# for l in open(\"pairs_Played.csv\"):\n",
    "#     if l.startswith(\"userID\"):\n",
    "#         # Write the header to the output file.\n",
    "#         predictions.write(l)\n",
    "#         continue\n",
    "#     u, g = l.strip().split(',')\n",
    "    \n",
    "#     # Extract features for the given (u, g) pair.\n",
    "#     # Feature 1: Jaccard similarity.\n",
    "#     max_similarity = 0\n",
    "#     if u in userPlayedGames:  # Make sure the user exists in the training data.\n",
    "#         for game_prime in userPlayedGames[u]:\n",
    "#             if game_prime in game_pair_similarities[game]:\n",
    "#                 similarity = game_pair_similarities[game][game_prime]\n",
    "#                 max_similarity = max(max_similarity, similarity)\n",
    "    \n",
    "#     # Feature 2: Popularity.\n",
    "#     popularity = gamePopularity[g]\n",
    "    \n",
    "#     # Make a prediction using the logistic regression model.\n",
    "#     pred = clf.predict([[max_similarity, popularity]])[0]  # clf is the trained logistic regression model.\n",
    "    \n",
    "#     # Write the prediction to the output file.\n",
    "#     predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "# # Close the prediction file.\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97138e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Would Play with CatBoost (idea came from office hour)\n",
    "# import gzip\n",
    "# from collections import defaultdict\n",
    "# import random\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load data with functions from stub\n",
    "# def readGz(path):\n",
    "#     for l in gzip.open(path, 'rt', encoding = \"utf-8\"):\n",
    "#         yield eval(l)\n",
    "\n",
    "# def readJSON(path):\n",
    "#     for l in gzip.open(path, 'rt', encoding = \"utf-8\"):\n",
    "#         d = eval(l)\n",
    "#         u = d['userID']\n",
    "#         try:\n",
    "#             g = d['gameID']\n",
    "#         except Exception as e:  # In case the 'gameID' attribute is missing.\n",
    "#             g = None\n",
    "#         yield u, g, d\n",
    "\n",
    "# allHours = []\n",
    "# for l in readJSON(\"train.json.gz\"):\n",
    "#     allHours.append(l)\n",
    "\n",
    "# # Split the data into training and validation sets.\n",
    "# hoursTrain = allHours[:165000]\n",
    "# hoursValid = allHours[165000:]\n",
    "\n",
    "# # Data structures for the would-play baseline (from baseline.py)\n",
    "# gameCount = defaultdict(int)  # Dictionary to keep track of how many times each game was played.\n",
    "# totalPlayed = 0  # Total number of games played.\n",
    "\n",
    "# # Find out which games a user hasn't played yet.\n",
    "# userPlayedGames = defaultdict(set)\n",
    "\n",
    "# # Populate gameCount dictionary and totalPlayed count.\n",
    "# for user, game, _ in readJSON(\"train.json.gz\"):\n",
    "#     gameCount[game] += 1\n",
    "#     totalPlayed += 1\n",
    "#     userPlayedGames[user].add(game)\n",
    "    \n",
    "# # Sort games by popularity (number of times played).\n",
    "# mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "# mostPopular.sort()\n",
    "# mostPopular.reverse()\n",
    "\n",
    "# # gamePopularity = {}\n",
    "# # for g in gameCount.keys():\n",
    "# #     idx = mostPopular.index((gameCount[g],g))\n",
    "# #     gamePopularity[g] = 1.0 - idx/len(mostPopular)\n",
    "\n",
    "# # Create validation set which includes both positive and negative samples.\n",
    "# allGames = list(gameCount.keys())  # All distinct games in our dataset.\n",
    "# trainSet = []\n",
    "# validSet = []\n",
    "\n",
    "# # Generate negative samples for the valid set.\n",
    "# for user, game, _ in hoursTrain:\n",
    "#     negativeGame = random.choice(allGames)\n",
    "#     while negativeGame in userPlayedGames[user]:\n",
    "#         negativeGame = random.choice(allGames)\n",
    "#     trainSet.append((user, game, 1))        # Positive example: The actual game played by the user\n",
    "#     trainSet.append((user, negativeGame, 0)) # Negative example: A randomly chosen game (not played by the user)\n",
    "\n",
    "# # Generate negative samples for the valid set.\n",
    "# for user, game, _ in hoursValid:\n",
    "#     negativeGame = random.choice(allGames)\n",
    "#     while negativeGame in userPlayedGames[user]:\n",
    "#         negativeGame = random.choice(allGames)\n",
    "#     validSet.append((user, game, 1))        # Positive example: The actual game played by the user\n",
    "#     validSet.append((user, negativeGame, 0)) # Negative example: A randomly chosen game (not played by the user)\n",
    "\n",
    "# # Create a dictionary with games as keys and sets of users who played them as values.\n",
    "# gameUsers = defaultdict(set)\n",
    "# for user, game, _ in hoursTrain:\n",
    "#     gameUsers[game].add(user)\n",
    "\n",
    "# # Calculate Jaccard similarity between two sets.\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     intersection = len(set1 & set2)\n",
    "#     union = len(set1 | set2)\n",
    "#     return intersection / union if union != 0 else 0\n",
    "\n",
    "# # Precompute Jaccard similarities for all game pairs.\n",
    "# game_pair_similarities = defaultdict(dict)\n",
    "# all_games = list(gameUsers.keys())\n",
    "\n",
    "# for i, game1 in enumerate(all_games):\n",
    "#     for j, game2 in enumerate(all_games):\n",
    "#         if j <= i:\n",
    "#             continue  # No need to compute similarity twice for the same pair\n",
    "#         similarity = jaccard_similarity(gameUsers[game1], gameUsers[game2])\n",
    "#         game_pair_similarities[game1][game2] = similarity\n",
    "#         game_pair_similarities[game2][game1] = similarity\n",
    "\n",
    "# # Prepare the features and labels.\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "\n",
    "# for user, game, actual in trainSet:\n",
    "#     # Feature 1: Jaccard similarity\n",
    "#     similarity = 0\n",
    "#     count = 0\n",
    "#     for game_prime in userPlayedGames[user]:\n",
    "#         if game_prime in game_pair_similarities[game]:\n",
    "#             similarity += game_pair_similarities[game][game_prime]\n",
    "#             count += 1\n",
    "#     if count == 0:\n",
    "#         similarity = 0\n",
    "#     else:\n",
    "#         similarity /= count\n",
    "#     # Feature 2: Popularity\n",
    "#     # popularity = gamePopularity[game]\n",
    "#     popularity = gameCount[game]\n",
    "#     X_train.append([similarity, popularity])\n",
    "#     # X_train.append([similarity])\n",
    "#     y_train.append(actual)\n",
    "    \n",
    "# X_train = pd.DataFrame(X_train, columns=['Similarity','Popularity'])\n",
    "# # X_train = pd.DataFrame(X_train, columns=['Similarity'])\n",
    "# y_train = pd.DataFrame(y_train, columns=['Label'])\n",
    "\n",
    "# X_valid = []\n",
    "# y_valid = []\n",
    "    \n",
    "# for user, game, actual in validSet:\n",
    "#     # Feature 1: Jaccard similarity\n",
    "#     similarity = 0\n",
    "#     count = 0\n",
    "#     for game_prime in userPlayedGames[user]:\n",
    "#         if game_prime in game_pair_similarities[game]:\n",
    "#             similarity += game_pair_similarities[game][game_prime]\n",
    "#             count += 1\n",
    "#     if count == 0:\n",
    "#         similarity = 0\n",
    "#     else:\n",
    "#         similarity /= count\n",
    "#     # Feature 2: Popularity\n",
    "#     # popularity = gamePopularity[game]\n",
    "#     popularity = gameCount[game]\n",
    "#     X_valid.append([similarity, popularity])\n",
    "#     # X_valid.append([similarity])\n",
    "#     y_valid.append(actual)\n",
    "\n",
    "# X_valid = pd.DataFrame(X_valid, columns=['Similarity','Popularity'])\n",
    "# # X_valid = pd.DataFrame(X_valid, columns=['Similarity'])\n",
    "# y_valid = pd.DataFrame(y_valid, columns=['Label'])\n",
    "\n",
    "# from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model = CatBoostClassifier(learning_rate = 0.01)\n",
    "\n",
    "# model.fit(\n",
    "#     X_train, y_train,\n",
    "# #    cat_features=categorical_features_indices,\n",
    "#     eval_set=(X_valid, y_valid),\n",
    "# #     logging_level='Verbose',  # you can uncomment this for text output\n",
    "# #    plot=True\n",
    "# );\n",
    "\n",
    "# # Open the test file and prediction file.\n",
    "# predictions = open(\"predictions_Played.csv\", 'w')\n",
    "\n",
    "# for l in open(\"pairs_Played.csv\"):\n",
    "#     if l.startswith(\"userID\"):\n",
    "#         # Write the header to the output file.\n",
    "#         predictions.write(l)\n",
    "#         continue\n",
    "#     u, g = l.strip().split(',')\n",
    "    \n",
    "#     # Extract features for the given (u, g) pair.\n",
    "#     # Feature 1: Jaccard similarity.\n",
    "#     similarity = 0\n",
    "#     count = 0\n",
    "#     if u in userPlayedGames:  # Make sure the user exists in the training data.\n",
    "#         for game_prime in userPlayedGames[u]:\n",
    "#             if game_prime in game_pair_similarities[game]:\n",
    "#                 similarity += game_pair_similarities[game][game_prime]\n",
    "#                 count += 1\n",
    "#         similarity /= count\n",
    "#     # Feature 2: Popularity.\n",
    "#     # popularity = gamePopularity[g]\n",
    "#     popularity = gameCount[game]\n",
    "#     # Make a prediction using the logistic regression model.\n",
    "#     pred = model.predict([[similarity, popularity]])[0]  # clf is the trained logistic regression model.\n",
    "#     # pred = model.predict([[similarity]])[0]\n",
    "    \n",
    "#     # Write the prediction to the output file.\n",
    "#     predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "# # Close the prediction file.\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b82818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Would Play with XGBoost (idea came from office hour) using optuna for best parameters\n",
    "\n",
    "# import gzip\n",
    "# from collections import defaultdict\n",
    "# import random\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load data with functions from stub\n",
    "# def readGz(path):\n",
    "#     for l in gzip.open(path, 'rt', encoding = \"utf-8\"):\n",
    "#         yield eval(l)\n",
    "\n",
    "# def readJSON(path):\n",
    "#     for l in gzip.open(path, 'rt', encoding = \"utf-8\"):\n",
    "#         d = eval(l)\n",
    "#         u = d['userID']\n",
    "#         try:\n",
    "#             g = d['gameID']\n",
    "#         except Exception as e:  # In case the 'gameID' attribute is missing.\n",
    "#             g = None\n",
    "#         yield u, g, d\n",
    "\n",
    "# allHours = []\n",
    "# for l in readJSON(\"train.json.gz\"):\n",
    "#     allHours.append(l)\n",
    "\n",
    "# # Split the data into training and validation sets.\n",
    "# hoursTrain = allHours[:165000]\n",
    "# hoursValid = allHours[165000:]\n",
    "\n",
    "# # Data structures for the would-play baseline (from baseline.py)\n",
    "# gameCount = defaultdict(int)  # Dictionary to keep track of how many times each game was played.\n",
    "# totalPlayed = 0  # Total number of games played.\n",
    "\n",
    "# # Find out which games a user hasn't played yet.\n",
    "# userPlayedGames = defaultdict(set)\n",
    "\n",
    "# # Populate gameCount dictionary and totalPlayed count.\n",
    "# for user, game, _ in readJSON(\"train.json.gz\"):\n",
    "#     gameCount[game] += 1\n",
    "#     totalPlayed += 1\n",
    "#     userPlayedGames[user].add(game)\n",
    "    \n",
    "# # Sort games by popularity (number of times played).\n",
    "# mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "# mostPopular.sort()\n",
    "# mostPopular.reverse()\n",
    "\n",
    "# # gamePopularity = {}\n",
    "# # for g in gameCount.keys():\n",
    "# #     idx = mostPopular.index((gameCount[g],g))\n",
    "# #     gamePopularity[g] = 1.0 - idx/len(mostPopular)\n",
    "\n",
    "# # Create validation set which includes both positive and negative samples.\n",
    "# allGames = list(gameCount.keys())  # All distinct games in our dataset.\n",
    "# trainSet = []\n",
    "# validSet = []\n",
    "\n",
    "# # Generate negative samples for the valid set.\n",
    "# for user, game, _ in hoursTrain:\n",
    "#     negativeGame = random.choice(allGames)\n",
    "#     while negativeGame in userPlayedGames[user]:\n",
    "#         negativeGame = random.choice(allGames)\n",
    "#     trainSet.append((user, game, 1))        # Positive example: The actual game played by the user\n",
    "#     trainSet.append((user, negativeGame, 0)) # Negative example: A randomly chosen game (not played by the user)\n",
    "\n",
    "# # Generate negative samples for the valid set.\n",
    "# for user, game, _ in hoursValid:\n",
    "#     negativeGame = random.choice(allGames)\n",
    "#     while negativeGame in userPlayedGames[user]:\n",
    "#         negativeGame = random.choice(allGames)\n",
    "#     validSet.append((user, game, 1))        # Positive example: The actual game played by the user\n",
    "#     validSet.append((user, negativeGame, 0)) # Negative example: A randomly chosen game (not played by the user)\n",
    "\n",
    "# # Create a dictionary with games as keys and sets of users who played them as values.\n",
    "# gameUsers = defaultdict(set)\n",
    "# for user, game, _ in hoursTrain:\n",
    "#     gameUsers[game].add(user)\n",
    "\n",
    "# # Calculate Jaccard similarity between two sets.\n",
    "# def jaccard_similarity(set1, set2):\n",
    "#     intersection = len(set1 & set2)\n",
    "#     union = len(set1 | set2)\n",
    "#     return intersection / union if union != 0 else 0\n",
    "\n",
    "# # Precompute Jaccard similarities for all game pairs.\n",
    "# game_pair_similarities = defaultdict(dict)\n",
    "# all_games = list(gameUsers.keys())\n",
    "\n",
    "# for i, game1 in enumerate(all_games):\n",
    "#     for j, game2 in enumerate(all_games):\n",
    "#         if j <= i:\n",
    "#             continue  # No need to compute similarity twice for the same pair\n",
    "#         similarity = jaccard_similarity(gameUsers[game1], gameUsers[game2])\n",
    "#         game_pair_similarities[game1][game2] = similarity\n",
    "#         game_pair_similarities[game2][game1] = similarity\n",
    "\n",
    "# # Prepare the features and labels.\n",
    "# X_train = []\n",
    "# y_train = []\n",
    "\n",
    "# for user, game, actual in trainSet:\n",
    "#     # Feature 1: Jaccard similarity\n",
    "#     similarity = 0\n",
    "#     count = 0\n",
    "#     for game_prime in userPlayedGames[user]:\n",
    "#         if game_prime in game_pair_similarities[game]:\n",
    "#             similarity += game_pair_similarities[game][game_prime]\n",
    "#             count += 1\n",
    "#     if count != 0:\n",
    "#         similarity /= count\n",
    "#     # Feature 2: Popularity\n",
    "#     # popularity = gamePopularity[game] \n",
    "#     # popularity = gameCount[game]\n",
    "#     # X_train.append([similarity, popularity])\n",
    "#     X_train.append([similarity])\n",
    "#     y_train.append(actual)\n",
    "\n",
    "# X_valid = []\n",
    "# y_valid = []\n",
    "    \n",
    "# for user, game, actual in validSet:\n",
    "#     # Feature 1: Jaccard similarity\n",
    "#     similarity = 0\n",
    "#     count = 0\n",
    "#     for game_prime in userPlayedGames[user]:\n",
    "#         if game_prime in game_pair_similarities[game]:\n",
    "#             similarity += game_pair_similarities[game][game_prime]\n",
    "#             count += 1\n",
    "#     if count != 0:\n",
    "#         similarity /= count\n",
    "#     # Feature 2: Popularity\n",
    "#     # popularity = gamePopularity[game]\n",
    "#     # popularity = gameCount[game]\n",
    "#     # X_valid.append([similarity, popularity])\n",
    "#     X_valid.append([similarity])\n",
    "#     y_valid.append(actual)\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# # 1. Define an objective function to be maximized.\n",
    "# def objective(trial):\n",
    "    \n",
    "#     dtrain = xgb.DMatrix(X_train, y_train)\n",
    "#     # 2. Suggest values of the hyperparameters using a trial object.\n",
    "#     param = {\n",
    "#         'silent': 1,\n",
    "#         'objective': 'binary:logistic',\n",
    "#         'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "#         'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "#         'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True)\n",
    "#     }\n",
    "\n",
    "#     bst = xgb.train(param, dtrain)\n",
    "#     y_predict = model.predict(X_valid)\n",
    "#     accuracy = sum([1 if i==j else 0 for i, j in zip (y_valid, y_predict)])/ len(y_valid)\n",
    "#     # print(f\"The current model accuracy on test set is {accuracy}\")\n",
    "#     return accuracy\n",
    "\n",
    "# # 3. Create a study object and optimize the objective function.\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=1000)\n",
    "\n",
    "# # Open the test file and prediction file.\n",
    "# predictions = open(\"predictions_Played.csv\", 'w')\n",
    "\n",
    "# for l in open(\"pairs_Played.csv\"):\n",
    "#     if l.startswith(\"userID\"):\n",
    "#         # Write the header to the output file.\n",
    "#         predictions.write(l)\n",
    "#         continue\n",
    "#     u, g = l.strip().split(',')\n",
    "    \n",
    "#     # Extract features for the given (u, g) pair.\n",
    "#     # Feature 1: Jaccard similarity.\n",
    "#     similarity = 0\n",
    "#     count = 0\n",
    "#     if u in userPlayedGames:  # Make sure the user exists in the training data.\n",
    "#         for game_prime in userPlayedGames[u]:\n",
    "#             if game_prime in game_pair_similarities[game]:\n",
    "#                 similarity += game_pair_similarities[game][game_prime]\n",
    "#                 count += 1\n",
    "#         similarity /= count\n",
    "#     # Feature 2: Popularity.\n",
    "#     # popularity = gamePopularity[g]\n",
    "#     # Spopularity = gameCount[g]\n",
    "    \n",
    "#     # Make a prediction using the logistic regression model.\n",
    "#     # pred = model.predict([[similarity, popularity]])[0]  # clf is the trained logistic regression model.\n",
    "#     pred = model.predict([similarity])[0]\n",
    "    \n",
    "#     # Write the prediction to the output file.\n",
    "#     predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "# # Close the prediction file.\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d66cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of my model on validation set is 0.7316231623162316\n"
     ]
    }
   ],
   "source": [
    "# Would Play with further feature engineering (idea from professor during the lecture)\n",
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Function to read data from a gzipped JSON file line by line\n",
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u, g, d\n",
    "\n",
    "# Reading and storing the dataset\n",
    "allHours = []\n",
    "for l in readJSON(\"train.json.gz\"):\n",
    "    allHours.append(l)\n",
    "\n",
    "# Splitting dataset into training and validation sets\n",
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]\n",
    "\n",
    "# Initializing data structures to store various information\n",
    "userPlayedGamesAll = defaultdict(set)\n",
    "allGamesCount = defaultdict(int)\n",
    "\n",
    "# Calculating frequencies and adding games and users to sets\n",
    "for user, game, _ in allHours:\n",
    "    userPlayedGamesAll[user].add(game)\n",
    "    allGamesCount[game] += 1\n",
    "\n",
    "# Preparing training and validation sets\n",
    "userPlayedGamesTrain = defaultdict(set)\n",
    "userPlayedGamesValid = defaultdict(set)\n",
    "\n",
    "# Populating the training set\n",
    "for user, game, _ in hoursTrain:\n",
    "    userPlayedGamesTrain[user].add(game)\n",
    "\n",
    "# Generating negative samples for the validation set\n",
    "hoursValidNegative = []\n",
    "for user, game, _ in hoursValid:\n",
    "    userPlayedGamesValid[user].add(game)\n",
    "    negativeGame = random.choice(list(allGamesCount.keys() - userPlayedGamesAll[user]))\n",
    "    hoursValidNegative.append((user, negativeGame, 0))\n",
    "    userPlayedGamesValid[user].add(negativeGame)\n",
    "\n",
    "# Reading test data\n",
    "userPlayedGamesTest = defaultdict(set)\n",
    "for l in open(\"pairs_Played.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        continue\n",
    "    u, g = l.strip().split(',')\n",
    "    userPlayedGamesTest[u].add(g)\n",
    "\n",
    "# Jaccard similarity function\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom if denom > 0 else 0\n",
    "\n",
    "# UserGamePredictor class with combined prediction strategies\n",
    "class UserGamePredictor():\n",
    "    def __init__(self, jaccard_threshold=0.025):\n",
    "        self.jaccard_threshold = jaccard_threshold\n",
    "    \n",
    "    def predict(self, user, game, gamesPerUser=None):\n",
    "        if gamesPerUser is None: gamesPerUser = userPlayedGamesTest[user]\n",
    "\n",
    "        # Frequency-based prediction\n",
    "        popularHalfGames = sorted(gamesPerUser, key=lambda x: allGamesCount[x], reverse=True)[:len(gamesPerUser) // 2]\n",
    "        freq_based_prediction = game in popularHalfGames\n",
    "\n",
    "        # Jaccard similarity-based prediction\n",
    "        maxSim = 0\n",
    "        usersWhoPlayedGame = set(userPlayedGamesAll[game])\n",
    "        for g2 in userPlayedGamesAll[user]:\n",
    "            sim = Jaccard(usersWhoPlayedGame, userPlayedGamesAll[g2])\n",
    "            if sim > maxSim:\n",
    "                maxSim = sim\n",
    "\n",
    "        jaccard_based_prediction = maxSim > self.jaccard_threshold and len(userPlayedGamesAll[game]) > 8\n",
    "\n",
    "        # Combining both strategies\n",
    "        return int(freq_based_prediction or jaccard_based_prediction)\n",
    "\n",
    "    # Validation method\n",
    "    def validate(self):\n",
    "        accuracy = 0\n",
    "        # Evaluate accuracy for positive samples\n",
    "        for user, game, _ in hoursValid:\n",
    "            accuracy += (self.predict(user, game, userPlayedGamesValid[user]) == 1)\n",
    "        # Evaluate accuracy for negative samples\n",
    "        for user, game, _ in hoursValidNegative:\n",
    "            accuracy += (self.predict(user, game, userPlayedGamesValid[user]) == 0)\n",
    "        # Calculate total accuracy\n",
    "        accuracy /= (len(hoursValid)+len(hoursValidNegative))\n",
    "        return accuracy\n",
    "\n",
    "# Instantiate the model and validate\n",
    "model = UserGamePredictor()\n",
    "accuracy = model.validate()\n",
    "print(f\"The accuracy of my model on validation set is {accuracy}\")\n",
    "\n",
    "# Writing predictions to a file\n",
    "predictions = open(\"predictions_Played.csv\", 'w')\n",
    "for l in open(\"pairs_Played.csv\"):\n",
    "    if l.startswith(\"userID\"):  # Write header line\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, g = l.strip().split(',')  # Split each line into userID and gameID\n",
    "    pred = model.predict(u, g)  # Make a prediction\n",
    "    predictions.write(u + ',' + g + ',' + str(pred) + '\\n')  # Write the prediction\n",
    "\n",
    "predictions.close()  # Close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e432437f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------lambda=4.9445-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9e899f1d6445d08333c7af00f69f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.9445, MSE: 2.9906277299\n",
      "-------------lambda=4.944599999999999-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c55985d608041a1bd7bfb3562976e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.944599999999999, MSE: 2.9906277297\n",
      "-------------lambda=4.944699999999999-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39e45c2448a48e89f1087b4c9d85a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.944699999999999, MSE: 2.9906277295\n",
      "-------------lambda=4.944799999999999-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5c191737ce47d2bf2047f2e30825e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.944799999999999, MSE: 2.9906277294\n",
      "-------------lambda=4.944899999999999-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceb58fa851f45a0ba54322af4b94726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.944899999999999, MSE: 2.9906277292\n",
      "-------------lambda=4.9449999999999985-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ced73e9fdd54f699db9c1d2da77a7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.9449999999999985, MSE: 2.9906277291\n",
      "-------------lambda=4.945099999999998-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff73704723464f689b224b38c804ac69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.945099999999998, MSE: 2.9906277290\n",
      "-------------lambda=4.945199999999998-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d2dc38d9c8494985ce09f7822058b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.945199999999998, MSE: 2.9906277289\n",
      "-------------lambda=4.945299999999998-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a12ddc2ce914d52972c6e6c159e4961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.945299999999998, MSE: 2.9906277288\n",
      "-------------lambda=4.945399999999998-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440bc517d0dc4519940585f53595c207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.945399999999998, MSE: 2.9906277288\n",
      "-------------lambda=4.945499999999997-------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46ce3c5adb444bb9d354ac5d4c5ecb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 4.945499999999997, MSE: 2.9906277287\n",
      "Best lambda: 4.945499999999997, with MSE: 2.9906277287\n"
     ]
    }
   ],
   "source": [
    "# Time Play (adopted from my hw3)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Calculate global average\n",
    "trainHours = [r[2]['hours_transformed'] for r in hoursTrain]\n",
    "globalAverage = sum(trainHours) / len(trainHours)\n",
    "\n",
    "# Initialize dictionaries\n",
    "hoursPerUserItem = defaultdict(float)\n",
    "gamesPerUser = defaultdict(int)\n",
    "usersPerItem = defaultdict(int)\n",
    "betaU = defaultdict(float)\n",
    "betaI = defaultdict(float)\n",
    "\n",
    "# Populate the dictionaries\n",
    "for user, game, d in hoursTrain:\n",
    "    hour = d['hours_transformed']\n",
    "    if user not in gamesPerUser:\n",
    "        gamesPerUser[user] = set()\n",
    "    if game not in usersPerItem:\n",
    "        usersPerItem[game] = set()\n",
    "    hoursPerUserItem[(user,game)] = hour\n",
    "    gamesPerUser[user].add(game)\n",
    "    usersPerItem[game].add(user)\n",
    "\n",
    "alpha = globalAverage  # Initialize alpha\n",
    "\n",
    "def iterate(lamb):\n",
    "    newAlpha = 0\n",
    "    newBetaU = {}\n",
    "    newBetaI = {}\n",
    "    \n",
    "    for key, value in hoursPerUserItem.items():\n",
    "        user, game = key\n",
    "        hour = value\n",
    "        newAlpha += (hour-betaU[user]-betaI[game])\n",
    "    newAlpha /= len(hoursPerUserItem.items())\n",
    "    \n",
    "    for u in betaU.keys():\n",
    "        newU = 0.0\n",
    "        for g in gamesPerUser[u]:\n",
    "            hour = hoursPerUserItem[(u,g)]\n",
    "            newU += (hour - newAlpha - betaI[g])\n",
    "        newU /= (lamb + len(gamesPerUser[u]))    \n",
    "        newBetaU[u] = newU\n",
    "\n",
    "    for i in betaI.keys():\n",
    "        newI = 0.0\n",
    "        for u in usersPerItem[i]:\n",
    "            hour = hoursPerUserItem[(u,i)]\n",
    "            newI += (hour - newAlpha - betaU[u])\n",
    "        newI /= (lamb + len(usersPerItem[i]))    \n",
    "        newBetaI[i] = newI\n",
    "            \n",
    "    return newAlpha, newBetaU, newBetaI\n",
    "\n",
    "# Initialize variables to store the best lambda and its corresponding MSE\n",
    "best_lambda = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "# Iterate over a range of lambda values\n",
    "for lamb in np.arange(4.9445,4.9455,0.0001):  # Adjust this range and values as necessary\n",
    "    \n",
    "    print(f'-------------lambda={lamb}-------------')\n",
    "    # Initialize beta values for this lambda\n",
    "    for u in gamesPerUser.keys():\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for g in usersPerItem.keys():\n",
    "        betaI[g] = 0\n",
    "\n",
    "    alpha = globalAverage  # Reset alpha\n",
    "\n",
    "    # Perform the iterations\n",
    "    for i in tqdm(range(100)):\n",
    "        alpha, betaU, betaI = iterate(lamb)\n",
    "        current_mse = 0.0\n",
    "        valid_mse = 0.0\n",
    "        for user, game, d in hoursValid:\n",
    "            hour = d['hours_transformed']\n",
    "            prediction = alpha + betaU.get(user,0)+ betaI.get(game,0)\n",
    "            current_mse += ((hour-prediction)**2)/len(hoursValid)\n",
    "        if (abs(valid_mse-current_mse)<1e-9):\n",
    "            break\n",
    "        valid_mse = current_mse\n",
    "\n",
    "    # Calculate MSE for this lambda\n",
    "    \n",
    "    print(f\"Lambda: {lamb}, MSE: {valid_mse:.10f}\")\n",
    "\n",
    "    # Update best lambda and MSE if current MSE is lower\n",
    "    if valid_mse < best_mse:\n",
    "        best_mse = valid_mse\n",
    "        best_lambda = lamb\n",
    "\n",
    "# Print the best lambda and its MSE\n",
    "print(f\"Best lambda: {best_lambda}, with MSE: {best_mse:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cc3ae13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36487629d65461ab8ed698829b5c03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue the time play to make prediction with best lambda\n",
    "for i in tqdm(range(100)):\n",
    "    alpha, betaU, betaI = iterate(4.95)\n",
    "    current_mse = 0.0\n",
    "    valid_mse = 0.0\n",
    "    for user, game, d in hoursValid:\n",
    "        hour = d['hours_transformed']\n",
    "        prediction = alpha + betaU.get(user,0)+ betaI.get(game,0)\n",
    "        current_mse += ((hour-prediction)**2)/len(hoursValid)\n",
    "    if (abs(valid_mse-current_mse)<1e-7):\n",
    "        break\n",
    "    valid_mse = current_mse\n",
    "    \n",
    "# Open the test file and prediction file.        \n",
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        # Write the header to the output file.\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, g = l.strip().split(',')\n",
    "        \n",
    "    bu, bi = betaU[u], betaI[g]\n",
    "    # Write the prediction to the output file.\n",
    "    predictions.write(u + ',' + g + ',' + str(alpha+bu+bi) + '\\n')\n",
    "\n",
    "# Close the prediction file.\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49098cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
