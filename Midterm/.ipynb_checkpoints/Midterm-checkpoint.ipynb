{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fadc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import random\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcdcf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a6d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = gzip.open(\"train.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2ef14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for l in z:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a06fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e80cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37e48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, ypred):\n",
    "    return np.mean((np.array(y) - np.array(ypred)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a5714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y, ypred):\n",
    "    return np.mean(np.abs(np.array(y) - np.array(ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9313a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['userID'],d['gameID']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "    \n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['date'])\n",
    "    \n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90c72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat1(d):\n",
    "    return [1, d['hours']]  # '1' for the bias term (θ0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e6ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for linear regression\n",
    "X = [feat1(d) for d in dataset]\n",
    "y = [len(d['text']) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the linear regression model\n",
    "mod = linear_model.LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "mod.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01a4668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting the value of θ1 and the Mean Squared Error\n",
    "theta_1 = mod.coef_[1]  # The coefficient for 'hours' feature\n",
    "mse_q1 = MSE(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32ed5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = [theta_1, mse_q1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0b7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q1'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e26bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a2aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median hours across the dataset\n",
    "median_hours = np.median([d['hours'] for d in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7246aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new feature extraction function incorporating the given transforms\n",
    "def feat2(d):\n",
    "    hours = d['hours']\n",
    "    hours_transformed = [\n",
    "        1,  # for θ0\n",
    "        hours,  # for θ1\n",
    "        math.log2(hours + 1),  # for θ2\n",
    "        hours**2,  # for θ3\n",
    "        1 if hours > median_hours else 0  # for θ4\n",
    "    ]\n",
    "    return hours_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8786922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat2(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1197d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2402ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE\n",
    "mse_q2 = MSE(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a5d7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = mse_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad4744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a690f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e524edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features based on the given binary indicators\n",
    "def feat3(d):\n",
    "    hours = d['hours']\n",
    "    return [1,  # Bias term for θ0\n",
    "            1 if hours > 1 else 0,    # δ(h>1) for θ1\n",
    "            1 if hours > 5 else 0,    # δ(h>5) for θ2\n",
    "            1 if hours > 10 else 0,   # δ(h>10) for θ3\n",
    "            1 if hours > 100 else 0,  # δ(h>100) for θ4\n",
    "            1 if hours > 1000 else 0] # δ(h>1000) for θ5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da7b030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat3(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44943983",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4439c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE\n",
    "mse_q3 = MSE(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20b470b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = mse_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3846bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69de975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67b6c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from the dataset\n",
    "def feat4(d):\n",
    "    return [1, len(d['text'])]  # Adding a constant term for θ0 and the review length for θ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "801b7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat4(d) for d in dataset]\n",
    "y = [d['hours'] for d in dataset]  # Extracting the number of hours played as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d57f7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c92c3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE and MAE\n",
    "mse = MSE(y, predictions)\n",
    "mae = MAE(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eff1f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:75735.7001827295,MSE:90.35613031984947\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE:{mse},MSE:{mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab2a5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = [mse, mae, \"MSE is sensitive to outliers, while MAE gives equal weight to all errors. The choice depends on the dataset's characteristics.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44b4eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q4'][:2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d0ee44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a333cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features (X)\n",
    "X = [feat4(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c841e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the labels (y) by applying the transformation log2(hours + 1)\n",
    "y_trans = [d['hours_transformed'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8e690b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y_trans)\n",
    "predictions_trans = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fcc3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE using the transformed target variable\n",
    "mse_trans = MSE(y_trans, predictions_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78d37258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the original hours values for MSE comparison\n",
    "original_hours = [d['hours'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62185cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the predictions back to the original scale by inverting the transformation\n",
    "predictions_untrans = [2**pred - 1 for pred in predictions_trans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b0db71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE on the untransformed (original hours) scale\n",
    "mse_untrans = MSE(original_hours, predictions_untrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ec7c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = [mse_trans, mse_untrans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55ee62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q5'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e41b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b538f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(hours, dim=100):\n",
    "    # Create a one-hot encoded vector for 'hours' with 'dim' dimensions\n",
    "    # Any value for 'hours' >= dim is encoded in the last position\n",
    "    vector = [0] * dim\n",
    "    index = min(int(hours), dim - 1)  # To ensure the index is within the bounds of 'vector'\n",
    "    vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "def feat6(d):\n",
    "    # Extract the one-hot encoding feature for the hours played\n",
    "    return one_hot(d['hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b530b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat6(d) for d in dataset]\n",
    "y = [len(d['text']) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3a35fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7f5d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "mses = {}\n",
    "bestC = None\n",
    "\n",
    "# Loop over the list of regularization strengths\n",
    "for c in [1, 10, 100, 1000, 10000]:\n",
    "    # Create and fit the Ridge regression model with current regularization strength\n",
    "    model = linear_model.Ridge(alpha=c)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Store the model\n",
    "    models[c] = model\n",
    "\n",
    "    # Predict and calculate MSE on validation set\n",
    "    yvalid_pred = model.predict(Xvalid)\n",
    "    mse_valid = MSE(yvalid, yvalid_pred)\n",
    "    mses[c] = mse_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3eadfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best alpha (regularization strength) based on the validation MSE\n",
    "bestC = min(mses, key=mses.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3743d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and calculate MSE on test set using the best model\n",
    "predictions_test = models[bestC].predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3fb98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_valid = mses[bestC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db93b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = MSE(ytest, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f49bfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = [bestC, mse_valid, mse_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8baaf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q6'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0aa5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "504f6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [d['hours_transformed'] for d in dataset]\n",
    "median = statistics.median(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "127534da",
   "metadata": {},
   "outputs": [],
   "source": [
    "notPlayed = [d for d in dataset if d['hours'] < 1]\n",
    "nNotPlayed = len(notPlayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d2bed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [median, nNotPlayed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1bdbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q7'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67e8ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30b18d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat8(d):\n",
    "    return [len(d['text'])]  # wrap the feature in a list as scikit-learn expects a 2D array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04607068",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat8(d) for d in dataset]\n",
    "y = [d['hours_transformed'] > median for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8bad8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LogisticRegression(class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "predictions = mod.predict(X) # Binary vector of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44a577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rates function to calculate the confusion matrix components\n",
    "def rates(predictions, y):\n",
    "    TP = sum(p and t for p, t in zip(predictions, y))\n",
    "    TN = sum(not p and not t for p, t in zip(predictions, y))\n",
    "    FP = sum(p and not t for p, t in zip(predictions, y))\n",
    "    FN = sum(not p and t for p, t in zip(predictions, y))\n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b96e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = rates(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1945455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BER = 0.5 * ((FP / (len(y) - sum(y))) + (FN / sum(y)))  # The average of the false positive rate and false negative rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f3004dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = [TP, TN, FP, FN, BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3623ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q8'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f0ba96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f10c0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probabilities of the positive class\n",
    "probs = mod.predict_proba(X)[:, 1]  # Probabilities of the positive class\n",
    "\n",
    "# Sort the instances by their probability of being positive\n",
    "sorted_indices = probs.argsort()[::-1]\n",
    "sorted_scores = probs[sorted_indices]\n",
    "sorted_labels = [y[idx] for idx in sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "177fa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "\n",
    "for k in [5, 10, 100, 1000]:\n",
    "    # Find the k-th score (0-indexed)\n",
    "    threshold_score = sorted_scores[k-1]\n",
    "    \n",
    "    # Find all indices where the score is greater than or equal to the threshold\n",
    "    # This handles ties by including all instances with the same score as the k-th element\n",
    "    tie_indices = np.where(sorted_scores >= threshold_score)[0]\n",
    "    \n",
    "    # Adjust k to account for ties\n",
    "    adjusted_k = tie_indices[-1] + 1\n",
    "    \n",
    "    # Compute precision\n",
    "    precision_at_k = np.sum(sorted_labels[:adjusted_k]) / adjusted_k\n",
    "    precs.append(precision_at_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a856ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q9'] = precs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d85ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q9'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26a3af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3102bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feat4(d) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "435b494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trans = [d['hours_transformed'] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4e5c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression(fit_intercept=False)\n",
    "mod.fit(X,y_trans)\n",
    "predictions_trans = mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "df3ed1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 4, num=101) # You can use more or fewer points.\n",
    "\n",
    "best_threshold = None\n",
    "lowest_BER = float('inf')\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Apply threshold to regression predictions to get binary classification\n",
    "    predictions_thresh = predictions_trans >= threshold\n",
    "    # Calculate TP, TN, FP, FN using confusion matrix\n",
    "    TP, TN, FP, FN = rates(predictions_thresh, y_trans)\n",
    "\n",
    "    # Compute BER\n",
    "    BER = 0.5 * (FN / (TP + FN) + FP / (TN + FP))\n",
    "    \n",
    "    # Store the best threshold and lowest BER\n",
    "    if BER < lowest_BER:\n",
    "        lowest_BER = BER\n",
    "        best_threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7846fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q10'] = [best_threshold, lowest_BER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9c718e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q10'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0795d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b66ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = dataset[:int(len(dataset)*0.9)]\n",
    "dataTest = dataset[int(len(dataset)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb03b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userMedian = defaultdict(list)\n",
    "itemMedian = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c359fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataTrain:\n",
    "    userMedian[entry['userID']].append(entry['hours'])\n",
    "    itemMedian[entry['gameID']].append(entry['hours'])\n",
    "\n",
    "# Compute medians using the collected playtimes\n",
    "userMedian = {user: statistics.median(playtimes) for user, playtimes in userMedian.items()}\n",
    "itemMedian = {item: statistics.median(playtimes) for item, playtimes in itemMedian.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "416c32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q11'] = [itemMedian['g35322304'], userMedian['u55351001']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "841df3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q11'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19378bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf9d7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_playtimes = [d['hours'] for d in dataTrain]\n",
    "global_median = statistics.median(global_playtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db5612a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f12(u,i):\n",
    "    # Function returns a single value (0 or 1)\n",
    "    # Check if item i has been seen before\n",
    "    if i in itemMedian and itemMedian[i] > global_median:\n",
    "        # If seen, return 1 if the item's median time played is above the global median\n",
    "        return 1\n",
    "    else:\n",
    "        # If the item hasn't been seen, check if the user's median time is above the global median\n",
    "        return 1 if i not in itemMedian and userMedian.get(u, 0) > global_median else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "91c6f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [f12(d['userID'], d['gameID']) for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b2a0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if d['hours'] > global_median else 0 for d in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d98b7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(pred == true for pred, true in zip(preds, y)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc9a4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q12'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f139511",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b356b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "483a29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "itemNames = {}\n",
    "\n",
    "for d in dataset:\n",
    "    user,item = d['userID'], d['gameID']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "225d6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    # Jaccard Similarity: |Intersection(s1, s2)| / |Union(s1, s2)|\n",
    "    numerator = len(s1.intersection(s2))\n",
    "    denominator = len(s1.union(s2))\n",
    "    return numerator / denominator if denominator > 0 else 0  # prevent division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b0799c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Most Similar Items Function\n",
    "def mostSimilar(i, func, N=10):\n",
    "    similarities = []\n",
    "    users_of_item_i = usersPerItem[i]\n",
    "    for other_item in usersPerItem:\n",
    "        if other_item == i: continue  # Skip comparing the item to itself\n",
    "        sim = func(users_of_item_i, usersPerItem[other_item])\n",
    "        similarities.append((sim, other_item))\n",
    "    # Sort based on similarity in descending order and return the top N\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a644542",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mostSimilar(dataset[0]['gameID'], Jaccard, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d2202e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q13'] = [ms[0][0], ms[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df55cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q13'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a266cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5325d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDict = {}\n",
    "\n",
    "for d in dataset:\n",
    "    u,i,playtime = d['userID'], d['gameID'], d['hours']\n",
    "    lab = 1 if playtime > global_median else -1 # Set the label based on a rule\n",
    "    ratingDict[(u,i)] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bdc9cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(i1, i2):\n",
    "    # Between two items\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for u in inter:\n",
    "        numer += ratingDict[(u,i1)]*ratingDict[(u,i2)]\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += ratingDict[(u,i1)]**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += ratingDict[(u,i2)]**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4c9166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilar14(i, func, N=10):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: continue\n",
    "        sim = func(i, i2)\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "908aabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mostSimilar14(dataset[0]['gameID'], Cosine, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fed0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q14'] = [ms[0][0], ms[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8308daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q14'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "61c3358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "63a5a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingDict = {}\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['userID'], d['gameID']\n",
    "    lab = d['hours_transformed']# Set the label based on a rule\n",
    "    ratingDict[(u,i)] = lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95406dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = mostSimilar14(dataset[0]['gameID'], Cosine, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae95f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q15'] = [ms[0][0], ms[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eac38017",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloatList(answers['Q15'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "436d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
